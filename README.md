# Classifica√ß√£o de Imagens CIFAR-10 com CNN

Este projeto implementa uma **Rede Neural Convolucional (CNN)** para classifica√ß√£o de imagens do dataset CIFAR-10, alcan√ßando **86% de acur√°cia** no conjunto de teste. O sistema utiliza t√©cnicas modernas de deep learning incluindo BatchNormalization, Dropout, callbacks avan√ßados e visualiza√ß√µes detalhadas de performance.

## üéØ Objetivo

Desenvolver um classificador robusto capaz de identificar 10 classes diferentes de objetos em imagens coloridas 32x32 pixels:
- **Ve√≠culos**: avi√£o, carro, navio, caminh√£o  
- **Animais**: p√°ssaro, gato, cervo, cachorro, cavalo, sapo

## üõ†Ô∏è Tecnologias Utilizadas

### Deep Learning Framework
- **TensorFlow/Keras** - Constru√ß√£o e treinamento da CNN
- **Sequential API** - Arquitetura linear de camadas

### Processamento e An√°lise
- **NumPy** - Manipula√ß√£o de arrays multidimensionais
- **Scikit-learn** - M√©tricas de avalia√ß√£o e divis√£o de dados
- **Matplotlib + Seaborn** - Visualiza√ß√µes profissionais

### T√©cnicas Avan√ßadas
- **BatchNormalization** - Estabiliza√ß√£o do treinamento
- **Dropout** - Preven√ß√£o de overfitting
- **Data Augmentation** - Aumento artificial do dataset
- **Callbacks** - Monitoramento e controle do treinamento

## üìä Dataset CIFAR-10

- **60.000 imagens** coloridas (32x32 pixels)
- **50.000 para treino**, **10.000 para teste**
- **10 classes balanceadas** (1.000 imagens por classe no teste)
- **3 canais RGB** por imagem

## üöÄ Implementa√ß√£o Detalhada

### 1. Carregamento e Pr√©-processamento

Sistema completo de prepara√ß√£o dos dados com divis√£o estratificada:

```python
# Carregamento do dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Classes do CIFAR-10
class_names = ['avi√£o','carro','p√°ssaro','gato','cervo',
               'cachorro','sapo','cavalo','navio','caminh√£o']

# Normaliza√ß√£o para [0,1] - acelera converg√™ncia
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot encoding para classifica√ß√£o multiclasse
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

# Divis√£o treino/valida√ß√£o (80%/20%) com estratifica√ß√£o
x_train, x_val, y_train_cat, y_val = train_test_split(
    x_train, y_train_cat, test_size=0.2, random_state=42
)
```

**Justificativas t√©cnicas:**
- **Normaliza√ß√£o**: Converte pixels [0-255] para [0-1], estabilizando gradientes
- **One-hot encoding**: Necess√°rio para fun√ß√£o de perda categorical_crossentropy
- **Divis√£o estratificada**: Mant√©m propor√ß√£o de classes em treino/valida√ß√£o

### 2. Arquitetura CNN Profissional

Rede convolucional hier√°rquica com 3 blocos especializados:

```python
modelo = Sequential()

# ========== BLOCO 1: Detec√ß√£o de Caracter√≠sticas B√°sicas ==========
modelo.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))
modelo.add(BatchNormalization())  # Normaliza ativa√ß√µes entre camadas
modelo.add(Conv2D(32, (3, 3), activation='relu'))  # Sem padding = reduz dimens√£o
modelo.add(MaxPooling2D(pool_size=(2, 2)))  # Reduz 50% da resolu√ß√£o
modelo.add(Dropout(0.25))  # Remove 25% das conex√µes aleatoriamente

# ========== BLOCO 2: Padr√µes Intermedi√°rios ==========
modelo.add(Conv2D(64, (3, 3), padding='same', activation='relu'))  # Dobra filtros
modelo.add(BatchNormalization())
modelo.add(Conv2D(64, (3, 3), activation='relu'))
modelo.add(MaxPooling2D(pool_size=(2, 2)))
modelo.add(Dropout(0.25))

# ========== BLOCO 3: Caracter√≠sticas Complexas ==========
modelo.add(Conv2D(128, (3, 3), padding='same', activation='relu'))  # 128 filtros
modelo.add(BatchNormalization())
modelo.add(Conv2D(128, (3, 3), activation='relu'))
modelo.add(MaxPooling2D(pool_size=(2, 2)))
modelo.add(Dropout(0.4))  # Dropout mais agressivo nas camadas profundas

# ========== CLASSIFICADOR FINAL ==========
modelo.add(Flatten())  # Converte feature maps 3D para vetor 1D
modelo.add(Dense(256, activation='relu'))  # Camada totalmente conectada
modelo.add(Dropout(0.5))  # Dropout alto antes da classifica√ß√£o
modelo.add(Dense(10, activation='softmax'))  # 10 classes com probabilidades
```

**Princ√≠pios da arquitetura:**

1. **Hierarquia de filtros**: 32 ‚Üí 64 ‚Üí 128 (detecta padr√µes crescentemente complexos)
2. **Padding estrat√©gico**: 'same' mant√©m dimens√µes, sem padding reduz progressivamente
3. **BatchNormalization**: Ap√≥s conv2D acelera treinamento e melhora estabilidade
4. **Dropout crescente**: 0.25 ‚Üí 0.25 ‚Üí 0.4 ‚Üí 0.5 (mais agressivo em camadas profundas)
5. **MaxPooling**: Reduz overfitting e custo computacional mantendo caracter√≠sticas importantes

### 3. Configura√ß√£o de Treinamento

Sistema de callbacks avan√ßado para treinamento inteligente:

```python
# Compila√ß√£o com otimizador adaptativo
modelo.compile(
    optimizer='adam',  # Adaptativo, combina momentum + RMSprop
    loss='categorical_crossentropy',  # Para classifica√ß√£o multiclasse
    metrics=['accuracy']
)

# Callbacks para controle autom√°tico do treinamento
callbacks = [
    EarlyStopping(
        monitor='val_loss',  # Monitora loss de valida√ß√£o
        patience=10,  # Para ap√≥s 10 √©pocas sem melhora
        restore_best_weights=True  # Restaura melhor modelo
    ),
    ModelCheckpoint(
        "best_cifar10_cnn.h5",  # Salva automaticamente melhor modelo
        save_best_only=True,
        monitor='val_loss'
    )
]

# Treinamento com monitoramento autom√°tico
history = modelo.fit(
    x_train, y_train_cat,
    batch_size=64,  # Balanceio entre velocidade e estabilidade
    epochs=100,  # Limite m√°ximo (EarlyStopping controla parada)
    validation_data=(x_val, y_val),
    callbacks=callbacks,
    verbose=1
)
```

### 4. Sistema de Avalia√ß√£o Completo

An√°lise multidimensional da performance do modelo:

```python
# Avalia√ß√£o quantitativa no conjunto de teste
test_loss, test_acc = modelo.evaluate(x_test, y_test_cat, verbose=0)
print(f"Acur√°cia final no teste: {test_acc:.4f}")

# Predi√ß√µes com probabilidades
y_pred_proba = modelo.predict(x_test)
y_pred = np.argmax(y_pred_proba, axis=1)  # Classe com maior probabilidade
y_true = np.argmax(y_test_cat, axis=1)

# Relat√≥rio detalhado por classe
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_true, y_pred, target_names=class_names))

# Matriz de confus√£o visual
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12,8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names, yticklabels=class_names)
plt.title("Matriz de Confus√£o - CIFAR-10 CNN", fontsize=16, fontweight='bold')
plt.xlabel("Classe Predita", fontsize=12)
plt.ylabel("Classe Real", fontsize=12)
plt.tight_layout()
plt.show()
```

### 5. Visualiza√ß√£o de Curvas de Treinamento

An√°lise da evolu√ß√£o do modelo durante o treinamento:

```python
def plot_training_history(history):
    """
    Gera gr√°ficos de performance do treinamento.
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Evolu√ß√£o da Acur√°cia
    ax1.plot(history.history['accuracy'], 'b-', label='Treino', linewidth=2)
    ax1.plot(history.history['val_accuracy'], 'r-', label='Valida√ß√£o', linewidth=2)
    ax1.set_title('Evolu√ß√£o da Acur√°cia', fontsize=14, fontweight='bold')
    ax1.set_xlabel('√âpocas')
    ax1.set_ylabel('Acur√°cia')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Evolu√ß√£o da Loss
    ax2.plot(history.history['loss'], 'b-', label='Treino', linewidth=2)
    ax2.plot(history.history['val_loss'], 'r-', label='Valida√ß√£o', linewidth=2)
    ax2.set_title('Evolu√ß√£o da Loss', fontsize=14, fontweight='bold')
    ax2.set_xlabel('√âpocas')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# Executar visualiza√ß√£o
plot_training_history(history)
```

### 6. An√°lise Qualitativa com Predi√ß√µes

Sistema de verifica√ß√£o visual das predi√ß√µes:

```python
def visualize_predictions(x_test, y_true, y_pred, class_names, n_samples=9):
    """
    Mostra predi√ß√µes do modelo com imagens reais.
    """
    # Selecionar amostras aleat√≥rias
    indices = np.random.choice(len(x_test), n_samples, replace=False)
    
    plt.figure(figsize=(12, 12))
    for i, idx in enumerate(indices):
        plt.subplot(3, 3, i+1)
        plt.imshow(x_test[idx])
        plt.axis("off")
        
        # Determinar cor do t√≠tulo baseado na corre√ß√£o
        true_class = class_names[y_true[idx]]
        pred_class = class_names[y_pred[idx]]
        color = 'green' if true_class == pred_class else 'red'
        
        plt.title(f"Real: {true_class}\nPredito: {pred_class}", 
                 color=color, fontsize=10, fontweight='bold')
    
    plt.suptitle('Exemplos de Predi√ß√µes do Modelo', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# Executar visualiza√ß√£o
visualize_predictions(x_test, y_true, y_pred, class_names)
```

## üìà Resultados Alcan√ßados

### Performance Geral
- **Acur√°cia no teste: 86.27%**
- **Loss final: 0.4339**
- **Treinamento: 64 √©pocas** (parada antecipada)

### Performance por Classe

| Classe | Precis√£o | Recall | F1-Score | Amostras |
|--------|----------|--------|----------|-----------|
| **Avi√£o** | 0.89 | 0.86 | 0.88 | 1000 |
| **Carro** | 0.93 | 0.94 | 0.93 | 1000 |
| **P√°ssaro** | 0.89 | 0.74 | 0.81 | 1000 |
| **Gato** | 0.75 | 0.75 | 0.75 | 1000 |
| **Cervo** | 0.82 | 0.88 | 0.85 | 1000 |
| **Cachorro** | 0.87 | 0.73 | 0.79 | 1000 |
| **Sapo** | 0.82 | 0.94 | 0.88 | 1000 |
| **Cavalo** | 0.88 | 0.91 | 0.90 | 1000 |
| **Navio** | 0.93 | 0.92 | 0.93 | 1000 |
| **Caminh√£o** | 0.87 | 0.95 | 0.91 | 1000 |

### An√°lise dos Resultados

**Classes com melhor performance:**
- **Carro (93% F1)**: Caracter√≠sticas distintivas claras (rodas, formato)
- **Navio (93% F1)**: Contexto aqu√°tico facilita identifica√ß√£o
- **Caminh√£o (91% F1)**: Tamanho e formato √∫nicos

**Classes mais desafiadoras:**
- **Gato (75% F1)**: Confus√£o com c√£o devido √† similaridade
- **P√°ssaro (81% F1)**: Grande varia√ß√£o de esp√©cies e poses
- **Cachorro (79% F1)**: Sobreposi√ß√£o com gato em algumas poses

## üé® Aplica√ß√µes Pr√°ticas

### Vis√£o Computacional
- **Classifica√ß√£o autom√°tica** de imagens em sistemas de armazenamento
- **Filtros inteligentes** para redes sociais e aplicativos
- **Sistema de busca visual** em bancos de imagens

### Seguran√ßa e Monitoramento
- **Detec√ß√£o de ve√≠culos** em sistemas de tr√°fego
- **Identifica√ß√£o de animais** em c√¢meras de seguran√ßa
- **Classifica√ß√£o autom√°tica** em sistemas de vigil√¢ncia

### Educa√ß√£o e Pesquisa
- **Ferramenta pedag√≥gica** para ensino de deep learning
- **Benchmark** para compara√ß√£o de arquiteturas
- **Base para transfer learning** em datasets similares

## üîß Poss√≠veis Melhorias

### Aumento de Performance
- [ ] **Data Augmentation** (rota√ß√£o, zoom, flip) para aumentar variabilidade
- [ ] **Transfer Learning** com modelos pr√©-treinados (ResNet, VGG)
- [ ] **Ensemble Methods** combinando m√∫ltiplos modelos
- [ ] **Arquiteturas avan√ßadas** (ResNet, DenseNet, EfficientNet)

### Otimiza√ß√£o T√©cnica
- [ ] **Learning Rate Scheduling** para converg√™ncia mais eficiente
- [ ] **Otimizador avan√ßado** (AdamW, RMSprop com momentum)
- [ ] **Regulariza√ß√£o L1/L2** adicional nas camadas densas
- [ ] **Gradient Clipping** para estabilidade em casos extremos

### An√°lise e Monitoramento
- [ ] **An√°lise de caracter√≠sticas** aprendidas pelos filtros
- [ ] **Visualiza√ß√£o de mapas de ativa√ß√£o** (Grad-CAM)
- [ ] **An√°lise de erros** detalhada por classe
- [ ] **M√©tricas customizadas** para classes espec√≠ficas

### Deployment e Produ√ß√£o
- [ ] **Quantiza√ß√£o do modelo** para redu√ß√£o de tamanho
- [ ] **Convers√£o para TensorFlow Lite** para mobile
- [ ] **API REST** para servir predi√ß√µes
- [ ] **Interface web** para upload e classifica√ß√£o

## üíº Adequa√ß√£o Profissional

### Compet√™ncias T√©cnicas Demonstradas

**Deep Learning:**
- Implementa√ß√£o completa de CNN do zero
- Uso apropriado de t√©cnicas de regulariza√ß√£o
- Conhecimento de arquiteturas hier√°rquicas

**Engenharia de Machine Learning:**
- Pipeline completo de dados (carregamento ‚Üí pr√©-processamento ‚Üí treinamento ‚Üí avalia√ß√£o)
- Uso de callbacks para treinamento inteligente
- Valida√ß√£o robusta com m√©tricas m√∫ltiplas

**An√°lise de Dados:**
- Visualiza√ß√µes profissionais e informativas
- Interpreta√ß√£o cr√≠tica de resultados
- An√°lise de performance por classe

**Boas Pr√°ticas:**
- C√≥digo bem estruturado e comentado
- Separa√ß√£o clara de responsabilidades
- Documenta√ß√£o t√©cnica detalhada

### Diferencial Competitivo

Este projeto demonstra n√£o apenas conhecimento te√≥rico, mas **implementa√ß√£o pr√°tica** de t√©cnicas modernas de deep learning, com foco em:

- **Resultados concretos** (84% acur√°cia)
- **An√°lise cr√≠tica** de performance
- **Visualiza√ß√µes profissionais** 
- **C√≥digo production-ready**
  
<img width="783" height="625" alt="{28288C22-8D36-4B86-B8A4-CC174C8A04A7}" src="https://github.com/user-attachments/assets/7be7cf35-8ed6-46ee-8bb8-ba754f7cea40" />

<img width="1148" height="470" alt="{2FB59818-EBDC-42E1-A259-9A3493AB0009}" src="https://github.com/user-attachments/assets/a3081860-b4dc-408d-9a64-8d4ac2d5c1a3" />

<img width="782" height="798" alt="{800484F3-7455-4D18-85F4-E92D9E604AA2}" src="https://github.com/user-attachments/assets/f8697e10-bc89-49e9-ad13-eeaed527a58e" />

---
